{
	"version": "2.0.0",
	"tasks": [
		{
			"label": "uv_sync",
			"type": "shell",
			"command": "~/.local/bin/uv sync"
		},
		{
			"label": "lanzar Gemma (para 8GB VRAM)",
			"type": "shell",
			"isBackground": true,
			"command": "~/programas/google_gemma-3-12b-it-Q4_K_M.llamafile --server --nobrowser -ngl 18 --gpu nvidia",
			"problemMatcher": {
				"background": {
					"activeOnStart": true,
					"beginsPattern": "^llama_model_loader(.*)$",
					"endsPattern": "^llama server listening at(.*)$"
				},
				"pattern": {
					"regexp": "^llama server listening at(.*)$",
					"message": 0
				}
			}
		},
		{
			"label": "lanzar DeepSeek (para 8GB VRAM)",
			"type": "shell",
			"isBackground": true,
			"command": "~/programas/DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.llamafile --server --nobrowser -ngl 32 --gpu nvidia",
			"problemMatcher": {
				"background": {
					"activeOnStart": true,
					"beginsPattern": "^llama_model_loader(.*)$",
					"endsPattern": "^llama server listening at(.*)$"
				},
				"pattern": {
					"regexp": "^llama server listening at(.*)$",
					"message": 0
				}
			}
		},
		{
			"label": "uv sync and llm",
			"dependsOn": [
				"uv_sync",
				"lanzar Gemma (para 8GB VRAM)"
			],
			"dependsOrder": "sequence"
		},
		{
			"label": "MCP Bridge (Simulated)",
			"type": "shell",
			"command": "~/.local/bin/uv run python mcp_bridge_simulated.py",
			"isBackground": true,
			"problemMatcher": []
		},
		{
			"label": "MCP Bridge Simulated v2",
			"type": "shell",
			"command": "~/.local/bin/uv run python mcp_bridge_simulated.py",
			"isBackground": true,
			"problemMatcher": []
		},
		{
			"label": "Simple MCP Bridge",
			"type": "shell",
			"command": "~/.local/bin/uv run python mcp_bridge_simple.py",
			"isBackground": true,
			"problemMatcher": []
		},
		{
			"label": "Simple MCP Bridge v2",
			"type": "shell",
			"command": "~/.local/bin/uv run python mcp_bridge_simple.py",
			"isBackground": true,
			"problemMatcher": []
		}
	]
}